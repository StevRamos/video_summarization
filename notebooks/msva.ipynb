{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/shuaman/video_sm/video_summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shuaman/video_sm/video_summarization\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import MSVA\n",
    "from src.utils import VSMDataset, parse_configuration\n",
    "from src.utils.utils_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "msva = MSVA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_weights_summe = \"/home/shuaman/video_sm/MSVA/model_weights/summe_random_non_overlap_0.5359.tar.pth\"\n",
    "path_weights_tvsum = \"/home/shuaman/video_sm/MSVA/model_weights/tvsum_random_non_overlap_0.6271.tar.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msva.load_state_dict(torch.load(path_weights_summe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_paths = {\n",
    "        'path_tvsum':\"/data/shuaman/video_summarization/datasets/processed_datasets/eccv16_dataset_tvsum_google_pool5.h5\",\n",
    "        'path_summe':\"/data/shuaman/video_summarization/datasets/processed_datasets/eccv16_dataset_summe_google_pool5.h5\",\n",
    "        'path_ovp':\"/data/shuaman/video_summarization/datasets/processed_datasets/eccv16_dataset_ovp_google_pool5.h5\",\n",
    "        'path_youtube':\"/data/shuaman/video_summarization/datasets/processed_datasets/eccv16_dataset_youtube_google_pool5.h5\",\n",
    "        'path_cosum':\"/data/shuaman/video_summarization/datasets/processed_datasets/dataset_cosum_processed.h5\",\n",
    "#         'path_tvsum':\"/data/shuaman/video_summarization/datasets/processed_datasets/dataset_tvsum_processed.h5\",\n",
    "#         'path_summe':\"/data/shuaman/video_summarization/datasets/processed_datasets/dataset_summe_processed.h5\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_use_feature = get_flags_features(\"i3d\", \"googlenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'googlenet': True,\n",
       " 'resnext': False,\n",
       " 'inceptionv3': False,\n",
       " 'i3d_rgb': True,\n",
       " 'i3d_flow': True,\n",
       " 'resnet3d': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_use_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'batch_size': 1,\n",
    "        'num_workers': 4\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_split = \"/home/shuaman/video_sm/video_summarization/splits/vasnet_splits/summe_splits.json\"\n",
    "splits = parse_configuration(path_split)\n",
    "split = splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_keys', 'test_keys'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/shuaman/video_summarization/datasets/processed_datasets/eccv16_dataset_summe_google_pool5.h5'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_paths = get_paths('summe', 'canonical', **dict_paths)\n",
    "dataset_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator, test_generator = get_dataloaders(dataset_paths, split, \n",
    "                                                     dict_use_feature, params,\n",
    "                                                    \"/data/shuaman/video_summarization/datasets/processed_datasets/transformations.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "it = 0\n",
    "for i in training_generator:\n",
    "    it += 1\n",
    "    continue\n",
    "print(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "it = 0\n",
    "for i in test_generator:\n",
    "    it += 1\n",
    "    continue\n",
    "print(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = init_optimizer(msva, 0.00005, 0.00001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sameCount = 0\n",
    "max_val_fscore = 0\n",
    "maxkt = 0\n",
    "maxsp = 0\n",
    "maxtrl = 0\n",
    "maxtsl = 0\n",
    "max_val_fscoreLs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(training_generator, criterion, optimizer):\n",
    "    msva.train()\n",
    "\n",
    "    avg_loss = []\n",
    "\n",
    "    for video_info, label in training_generator:\n",
    "        \n",
    "        target = (label['gtscore'].squeeze(0)).cpu().numpy()\n",
    "        features = [(video_info[key].squeeze(0)).cpu().numpy() for key in video_info.keys() if 'features' in  key]\n",
    "\n",
    "        shape_desire = target.shape[0]\n",
    "        features = [cv2.resize(feature, (feature.shape[1],shape_desire), interpolation = cv2.INTER_AREA) for feature in features]\n",
    "\n",
    "        features = [torch.from_numpy(feature).unsqueeze(0) for feature in features]\n",
    "        target =  torch.from_numpy(target).unsqueeze(0)\n",
    "\n",
    "        target -= target.min()\n",
    "        target = np.true_divide(target, target.max())\n",
    "\n",
    "        target = target.float().to(device)\n",
    "        features = [feature.float().to(device) for feature in features]\n",
    "        seq_len = features[0].shape[1]\n",
    "\n",
    "        y, _ = msva(features, seq_len)\n",
    "\n",
    "        loss = criterion(y, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss.append(loss.item())\n",
    "\n",
    "    avg_loss = np.mean(np.array(avg_loss))\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSVA(\n",
       "  (att1_3): SelfAttention(\n",
       "    (K): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "    (Q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "    (V): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "    (output_linear): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (ka1_3): Linear(in_features=1024, out_features=365, bias=True)\n",
       "  (kb): Linear(in_features=365, out_features=365, bias=True)\n",
       "  (kc): Linear(in_features=365, out_features=512, bias=True)\n",
       "  (kd): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (sig): Sigmoid()\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (softmax): Softmax(dim=0)\n",
       "  (layer_norm_y_1_3): LayerNorm()\n",
       "  (layer_norm_y_4): LayerNorm()\n",
       "  (layer_norm_kc): LayerNorm()\n",
       "  (layer_norm_kd): LayerNorm()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msva.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import generate_summary, evaluate_summary\n",
    "from scipy.stats import kendalltau, spearmanr, rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_function(test_generator):\n",
    "    msva.eval()\n",
    "\n",
    "    avg_loss = []\n",
    "    fms = []\n",
    "    kts = []\n",
    "    sps = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for video_info, label in test_generator:\n",
    "\n",
    "            target = (label['gtscore'].squeeze(0)).cpu().numpy()\n",
    "            features = [(video_info[key].squeeze(0)).cpu().numpy() for key in video_info.keys() if 'features' in  key]\n",
    "\n",
    "            shape_desire = target.shape[0]\n",
    "            features = [cv2.resize(feature, (feature.shape[1],shape_desire), interpolation = cv2.INTER_AREA) for feature in features]\n",
    "\n",
    "            features = [torch.from_numpy(feature).unsqueeze(0) for feature in features]\n",
    "            target =  torch.from_numpy(target).unsqueeze(0)\n",
    "\n",
    "            target -= target.min()\n",
    "            target = np.true_divide(target, target.max())\n",
    "\n",
    "            target = target.float().to(device)\n",
    "            features = [feature.float().to(device) for feature in features]\n",
    "\n",
    "            y, _ = msva(features, shape_desire)\n",
    "\n",
    "            criterion = torch.nn.MSELoss()\n",
    "            criterion.to(device)\n",
    "\n",
    "            test_loss = criterion(y, target)\n",
    "\n",
    "            avg_loss.append(test_loss.item())\n",
    "            summary = y[0].detach().cpu().numpy()\n",
    "\n",
    "            machine_summary = generate_summary(summary, (video_info[\"change_points\"].squeeze(0)).cpu().numpy(),\n",
    "                                              (video_info[\"n_frames\"].squeeze(0)).cpu().numpy(), (video_info[\"n_frame_per_seg\"].squeeze(0)).cpu().numpy(),\n",
    "                                                (video_info[\"picks\"].squeeze(0)).cpu().numpy())\n",
    "\n",
    "            eval_metric = 'avg' if video_info[\"name_dataset\"][0] == \"tvsum\" else 'max'\n",
    "            fm, _, _ = evaluate_summary(machine_summary, (label[\"user_summary\"].squeeze(0)).cpu().numpy(),\n",
    "                                            eval_metric)\n",
    "\n",
    "            fms.append(fm)\n",
    "            y_pred2 = machine_summary\n",
    "            y_true2 = (label[\"user_summary\"].squeeze(0)).cpu().numpy().mean(axis=0)\n",
    "            pS = spearmanr(y_pred2, y_true2)[0]\n",
    "            kT = kendalltau(rankdata(-np.array(y_true2)), rankdata(-np.array(y_pred2)))[0]\n",
    "            kts.append(kT)\n",
    "            sps.append(pS)\n",
    "\n",
    "\n",
    "    f_score = np.mean(fms)\n",
    "    kt = np.mean(kts)\n",
    "    sp = np.mean(sps)\n",
    "    avg_loss = np.mean(np.array(avg_loss))\n",
    "\n",
    "    return f_score, kt, sp, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    train_loss = train_step(training_generator, criterion, optimizer)\n",
    "    f_score, kt, sp, test_loss = eval_function(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12407581160149403"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1102586827115101"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43061976583898265"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03655345905572176"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vsm_kernel",
   "language": "python",
   "name": "vsm_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
